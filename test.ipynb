{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama_index.core\n",
      "  Downloading llama_index_core-0.10.29-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting llama_index\n",
      "  Downloading llama_index-0.10.29-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting openai\n",
      "  Using cached openai-1.17.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting llama_index.llms.openai\n",
      "  Using cached llama_index_llms_openai-0.1.15-py3-none-any.whl.metadata (559 bytes)\n",
      "Collecting llama_index.embeddings.openai\n",
      "  Using cached llama_index_embeddings_openai-0.1.7-py3-none-any.whl.metadata (603 bytes)\n",
      "Collecting PyYAML>=6.0.1 (from llama_index.core)\n",
      "  Using cached PyYAML-6.0.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./.venv/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama_index.core) (2.0.29)\n",
      "Collecting aiohttp<4.0.0,>=3.8.6 (from llama_index.core)\n",
      "  Using cached aiohttp-3.9.4-cp310-cp310-macosx_10_9_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting dataclasses-json (from llama_index.core)\n",
      "  Using cached dataclasses_json-0.6.4-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama_index.core)\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama_index.core)\n",
      "  Using cached dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting fsspec>=2023.5.0 (from llama_index.core)\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx (from llama_index.core)\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting llamaindex-py-client<0.2.0,>=0.1.18 (from llama_index.core)\n",
      "  Using cached llamaindex_py_client-0.1.18-py3-none-any.whl.metadata (760 bytes)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./.venv/lib/python3.10/site-packages (from llama_index.core) (1.6.0)\n",
      "Collecting networkx>=3.0 (from llama_index.core)\n",
      "  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting nltk<4.0.0,>=3.8.1 (from llama_index.core)\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (from llama_index.core) (1.26.4)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (from llama_index.core) (2.2.2)\n",
      "Collecting pillow>=9.0.0 (from llama_index.core)\n",
      "  Using cached pillow-10.3.0-cp310-cp310-macosx_10_10_x86_64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./.venv/lib/python3.10/site-packages (from llama_index.core) (2.31.0)\n",
      "Collecting tenacity<9.0.0,>=8.2.0 (from llama_index.core)\n",
      "  Using cached tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting tiktoken>=0.3.3 (from llama_index.core)\n",
      "  Using cached tiktoken-0.6.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting tqdm<5.0.0,>=4.66.1 (from llama_index.core)\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./.venv/lib/python3.10/site-packages (from llama_index.core) (4.11.0)\n",
      "Collecting typing-inspect>=0.8.0 (from llama_index.core)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting wrapt (from llama_index.core)\n",
      "  Using cached wrapt-1.16.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama_index)\n",
      "  Using cached llama_index_agent_openai-0.2.2-py3-none-any.whl.metadata (677 bytes)\n",
      "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama_index)\n",
      "  Using cached llama_index_cli-0.1.11-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama_index)\n",
      "  Using cached llama_index_indices_managed_llama_cloud-0.1.5-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama_index)\n",
      "  Using cached llama_index_legacy-0.9.48-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama_index)\n",
      "  Using cached llama_index_multi_modal_llms_openai-0.1.5-py3-none-any.whl.metadata (677 bytes)\n",
      "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama_index)\n",
      "  Using cached llama_index_program_openai-0.1.5-py3-none-any.whl.metadata (715 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama_index)\n",
      "  Using cached llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\n",
      "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama_index)\n",
      "  Downloading llama_index_readers_file-0.1.18-py3-none-any.whl.metadata (979 bytes)\n",
      "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama_index)\n",
      "  Using cached llama_index_readers_llama_parse-0.1.4-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.10/site-packages (from openai) (4.3.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.10/site-packages (from openai) (2.7.0)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.6->llama_index.core)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.6->llama_index.core)\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.6->llama_index.core)\n",
      "  Using cached frozenlist-1.4.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.6->llama_index.core)\n",
      "  Using cached multidict-6.0.5-cp310-cp310-macosx_10_9_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.6->llama_index.core)\n",
      "  Using cached yarl-1.9.4-cp310-cp310-macosx_10_9_x86_64.whl.metadata (31 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp<4.0.0,>=3.8.6->llama_index.core)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.10/site-packages (from httpx->llama_index.core) (2024.2.2)\n",
      "Collecting httpcore==1.* (from httpx->llama_index.core)\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama_index.core)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting beautifulsoup4<5.0.0,>=4.12.3 (from llama-index-readers-file<0.2.0,>=0.1.4->llama_index)\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama_index)\n",
      "  Using cached pypdf-4.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama_index)\n",
      "  Using cached striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse<0.5.0,>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama_index)\n",
      "  Downloading llama_parse-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting click (from nltk<4.0.0,>=3.8.1->llama_index.core)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk<4.0.0,>=3.8.1->llama_index.core)\n",
      "  Using cached joblib-1.4.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk<4.0.0,>=3.8.1->llama_index.core)\n",
      "  Using cached regex-2023.12.25-cp310-cp310-macosx_10_9_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in ./.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.18.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests>=2.31.0->llama_index.core) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests>=2.31.0->llama_index.core) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.venv/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama_index.core) (3.0.3)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama_index.core)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama_index.core)\n",
      "  Using cached marshmallow-3.21.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas->llama_index.core) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas->llama_index.core) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas->llama_index.core) (2024.1)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama_index)\n",
      "  Using cached soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in ./.venv/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama_index.core) (24.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama_index.core) (1.16.0)\n",
      "Downloading llama_index_core-0.10.29-py3-none-any.whl (15.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading llama_index-0.10.29-py3-none-any.whl (6.9 kB)\n",
      "Using cached openai-1.17.1-py3-none-any.whl (268 kB)\n",
      "Using cached llama_index_llms_openai-0.1.15-py3-none-any.whl (10 kB)\n",
      "Using cached llama_index_embeddings_openai-0.1.7-py3-none-any.whl (6.0 kB)\n",
      "Using cached aiohttp-3.9.4-cp310-cp310-macosx_10_9_x86_64.whl (400 kB)\n",
      "Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Using cached llama_index_agent_openai-0.2.2-py3-none-any.whl (12 kB)\n",
      "Using cached llama_index_cli-0.1.11-py3-none-any.whl (26 kB)\n",
      "Using cached llama_index_indices_managed_llama_cloud-0.1.5-py3-none-any.whl (6.7 kB)\n",
      "Using cached llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
      "Using cached llama_index_multi_modal_llms_openai-0.1.5-py3-none-any.whl (5.8 kB)\n",
      "Using cached llama_index_program_openai-0.1.5-py3-none-any.whl (4.1 kB)\n",
      "Using cached llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_readers_file-0.1.18-py3-none-any.whl (36 kB)\n",
      "Using cached llama_index_readers_llama_parse-0.1.4-py3-none-any.whl (2.5 kB)\n",
      "Using cached llamaindex_py_client-0.1.18-py3-none-any.whl (136 kB)\n",
      "Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached pillow-10.3.0-cp310-cp310-macosx_10_10_x86_64.whl (3.5 MB)\n",
      "Using cached PyYAML-6.0.1-cp310-cp310-macosx_10_9_x86_64.whl (189 kB)\n",
      "Using cached tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Using cached tiktoken-0.6.0-cp310-cp310-macosx_10_9_x86_64.whl (999 kB)\n",
      "Using cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached wrapt-1.16.0-cp310-cp310-macosx_10_9_x86_64.whl (37 kB)\n",
      "Using cached dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached frozenlist-1.4.1-cp310-cp310-macosx_10_9_x86_64.whl (53 kB)\n",
      "Downloading llama_parse-0.4.1-py3-none-any.whl (7.3 kB)\n",
      "Using cached marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
      "Using cached multidict-6.0.5-cp310-cp310-macosx_10_9_x86_64.whl (30 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Using cached pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
      "Using cached regex-2023.12.25-cp310-cp310-macosx_10_9_x86_64.whl (296 kB)\n",
      "Using cached striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Using cached yarl-1.9.4-cp310-cp310-macosx_10_9_x86_64.whl (81 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached joblib-1.4.0-py3-none-any.whl (301 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: striprtf, dirtyjson, wrapt, tqdm, tenacity, soupsieve, regex, PyYAML, pypdf, pillow, networkx, mypy-extensions, multidict, marshmallow, joblib, h11, fsspec, frozenlist, distro, click, attrs, async-timeout, yarl, typing-inspect, tiktoken, nltk, httpcore, deprecated, beautifulsoup4, aiosignal, httpx, dataclasses-json, aiohttp, openai, llamaindex-py-client, llama-index-legacy, llama_index.core, llama-parse, llama-index-readers-file, llama_index.llms.openai, llama-index-indices-managed-llama-cloud, llama_index.embeddings.openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama_index\n",
      "Successfully installed PyYAML-6.0.1 aiohttp-3.9.4 aiosignal-1.3.1 async-timeout-4.0.3 attrs-23.2.0 beautifulsoup4-4.12.3 click-8.1.7 dataclasses-json-0.6.4 deprecated-1.2.14 dirtyjson-1.0.8 distro-1.9.0 frozenlist-1.4.1 fsspec-2024.3.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 joblib-1.4.0 llama-index-agent-openai-0.2.2 llama-index-cli-0.1.11 llama-index-indices-managed-llama-cloud-0.1.5 llama-index-legacy-0.9.48 llama-index-multi-modal-llms-openai-0.1.5 llama-index-program-openai-0.1.5 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.18 llama-index-readers-llama-parse-0.1.4 llama-parse-0.4.1 llama_index-0.10.29 llama_index.core-0.10.29 llama_index.embeddings.openai-0.1.7 llama_index.llms.openai-0.1.15 llamaindex-py-client-0.1.18 marshmallow-3.21.1 multidict-6.0.5 mypy-extensions-1.0.0 networkx-3.3 nltk-3.8.1 openai-1.17.1 pillow-10.3.0 pypdf-4.2.0 regex-2023.12.25 soupsieve-2.5 striprtf-0.0.26 tenacity-8.2.3 tiktoken-0.6.0 tqdm-4.66.2 typing-inspect-0.9.0 wrapt-1.16.0 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip install  llama_index.core llama_index openai llama_index.llms.openai llama_index.embeddings.openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting fastapi\n",
      "  Using cached fastapi-0.110.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting pydantic\n",
      "  Using cached pydantic-2.7.0-py3-none-any.whl.metadata (103 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.2-cp310-cp310-macosx_10_9_x86_64.whl.metadata (19 kB)\n",
      "Collecting sqlalchemy\n",
      "  Using cached SQLAlchemy-2.0.29-cp310-cp310-macosx_10_9_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Using cached charset_normalizer-3.3.2-cp310-cp310-macosx_10_9_x86_64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi)\n",
      "  Using cached starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.10/site-packages (from fastapi) (4.11.0)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic)\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.18.1 (from pydantic)\n",
      "  Using cached pydantic_core-2.18.1-cp310-cp310-macosx_10_12_x86_64.whl.metadata (6.5 kB)\n",
      "Collecting numpy>=1.22.4 (from pandas)\n",
      "  Using cached numpy-1.26.4-cp310-cp310-macosx_10_9_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy)\n",
      "  Using cached greenlet-3.0.3-cp310-cp310-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Collecting anyio<5,>=3.4.0 (from starlette<0.38.0,>=0.37.2->fastapi)\n",
      "  Using cached anyio-4.3.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting sniffio>=1.1 (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi) (1.2.0)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Using cached fastapi-0.110.1-py3-none-any.whl (91 kB)\n",
      "Using cached pydantic-2.7.0-py3-none-any.whl (407 kB)\n",
      "Using cached pydantic_core-2.18.1-cp310-cp310-macosx_10_12_x86_64.whl (1.9 MB)\n",
      "Using cached pandas-2.2.2-cp310-cp310-macosx_10_9_x86_64.whl (12.6 MB)\n",
      "Using cached SQLAlchemy-2.0.29-cp310-cp310-macosx_10_9_x86_64.whl (2.1 MB)\n",
      "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp310-cp310-macosx_10_9_x86_64.whl (122 kB)\n",
      "Using cached greenlet-3.0.3-cp310-cp310-macosx_11_0_universal2.whl (270 kB)\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached numpy-1.26.4-cp310-cp310-macosx_10_9_x86_64.whl (20.6 MB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Using cached anyio-4.3.0-py3-none-any.whl (85 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: pytz, urllib3, tzdata, sniffio, pydantic-core, numpy, idna, greenlet, charset-normalizer, certifi, annotated-types, sqlalchemy, requests, pydantic, pandas, anyio, starlette, fastapi\n",
      "Successfully installed annotated-types-0.6.0 anyio-4.3.0 certifi-2024.2.2 charset-normalizer-3.3.2 fastapi-0.110.1 greenlet-3.0.3 idna-3.7 numpy-1.26.4 pandas-2.2.2 pydantic-2.7.0 pydantic-core-2.18.1 pytz-2024.1 requests-2.31.0 sniffio-1.3.1 sqlalchemy-2.0.29 starlette-0.37.2 tzdata-2024.1 urllib3-2.2.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install requests fastapi pydantic pandas sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Using cached chromadb-0.4.24-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting llama_index.vector_stores.chroma\n",
      "  Using cached llama_index_vector_stores_chroma-0.1.6-py3-none-any.whl.metadata (654 bytes)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Using cached build-1.2.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: requests>=2.28 in ./.venv/lib/python3.10/site-packages (from chromadb) (2.31.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in ./.venv/lib/python3.10/site-packages (from chromadb) (2.7.0)\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
      "  Using cached chroma_hnswlib-0.7.3-cp310-cp310-macosx_10_9_x86_64.whl.metadata (252 bytes)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in ./.venv/lib/python3.10/site-packages (from chromadb) (0.110.1)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached uvicorn-0.29.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in ./.venv/lib/python3.10/site-packages (from chromadb) (1.26.4)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Using cached posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./.venv/lib/python3.10/site-packages (from chromadb) (4.11.0)\n",
      "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
      "  Using cached pulsar_client-3.5.0-cp310-cp310-macosx_10_15_universal2.whl.metadata (1.0 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Using cached onnxruntime-1.17.3-cp310-cp310-macosx_11_0_universal2.whl.metadata (4.4 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_api-1.24.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_sdk-1.24.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb)\n",
      "  Using cached tokenizers-0.15.2-cp310-cp310-macosx_10_12_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Using cached PyPika-0.48.9-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tqdm>=4.65.0 in ./.venv/lib/python3.10/site-packages (from chromadb) (4.66.2)\n",
      "Collecting overrides>=7.3.1 (from chromadb)\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Using cached importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb)\n",
      "  Using cached grpcio-1.62.1-cp310-cp310-macosx_12_0_universal2.whl.metadata (4.0 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Using cached bcrypt-4.1.2-cp39-abi3-macosx_10_12_universal2.whl.metadata (9.5 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Using cached typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Using cached kubernetes-29.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in ./.venv/lib/python3.10/site-packages (from chromadb) (8.2.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in ./.venv/lib/python3.10/site-packages (from chromadb) (6.0.1)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Using cached mmh3-4.1.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (13 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb)\n",
      "  Using cached orjson-3.10.0-cp310-cp310-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (49 kB)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in ./.venv/lib/python3.10/site-packages (from llama_index.vector_stores.chroma) (0.10.29)\n",
      "Requirement already satisfied: packaging>=19.1 in ./.venv/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (24.0)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Using cached pyproject_hooks-1.0.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting tomli>=1.1.0 (from build>=1.0.3->chromadb)\n",
      "  Using cached tomli-2.0.1-py3-none-any.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in ./.venv/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb) (0.37.2)\n",
      "Requirement already satisfied: certifi>=14.05.14 in ./.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2024.2.2)\n",
      "Requirement already satisfied: six>=1.9.0 in ./.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in ./.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached google_auth-2.29.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached websocket_client-1.7.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in ./.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./.venv/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (3.9.4)\n",
      "Requirement already satisfied: dataclasses-json in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (2024.3.1)\n",
      "Requirement already satisfied: httpx in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (0.1.18)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (3.8.1)\n",
      "Requirement already satisfied: openai>=1.1.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (1.17.1)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (2.2.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (10.3.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (0.6.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (1.16.0)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached protobuf-5.26.1-cp37-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Collecting sympy (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting importlib-metadata<=7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Using cached importlib_metadata-7.0.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached googleapis_common_protos-1.63.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting opentelemetry-proto==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_proto-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-instrumentation==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation-0.45b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-util-http==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_util_http-0.45b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in ./.venv/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (63.2.0)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.10/site-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in ./.venv/lib/python3.10/site-packages (from pydantic>=1.9->chromadb) (2.18.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests>=2.28->chromadb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests>=2.28->chromadb) (3.7)\n",
      "Collecting huggingface_hub<1.0,>=0.16.4 (from tokenizers>=0.13.2->chromadb)\n",
      "  Using cached huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer>=0.9.0->chromadb)\n",
      "  Using cached rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: h11>=0.8 in ./.venv/lib/python3.10/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached httptools-0.6.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached uvloop-0.19.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached watchfiles-0.21.0-cp310-cp310-macosx_10_7_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached websockets-12.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (4.0.3)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting filelock (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb)\n",
      "  Using cached filelock-3.13.4-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting zipp>=0.5 (from importlib-metadata<=7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb)\n",
      "  Using cached zipp-3.18.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (4.3.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (1.0.5)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (1.3.1)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (1.4.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (2023.12.25)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (1.9.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer>=0.9.0->chromadb)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.17.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.venv/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (1.0.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (3.21.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (2024.1)\n",
      "Collecting mpmath>=0.19 (from sympy->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama_index.vector_stores.chroma) (1.2.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Using cached chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
      "Using cached chroma_hnswlib-0.7.3-cp310-cp310-macosx_10_9_x86_64.whl (219 kB)\n",
      "Using cached llama_index_vector_stores_chroma-0.1.6-py3-none-any.whl (4.7 kB)\n",
      "Using cached bcrypt-4.1.2-cp39-abi3-macosx_10_12_universal2.whl (528 kB)\n",
      "Using cached build-1.2.1-py3-none-any.whl (21 kB)\n",
      "Using cached grpcio-1.62.1-cp310-cp310-macosx_12_0_universal2.whl (10.0 MB)\n",
      "Using cached kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
      "Using cached mmh3-4.1.0-cp310-cp310-macosx_10_9_x86_64.whl (29 kB)\n",
      "Using cached onnxruntime-1.17.3-cp310-cp310-macosx_11_0_universal2.whl (14.8 MB)\n",
      "Using cached opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl (17 kB)\n",
      "Using cached opentelemetry_proto-1.24.0-py3-none-any.whl (50 kB)\n",
      "Using cached opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl (11 kB)\n",
      "Using cached opentelemetry_instrumentation-0.45b0-py3-none-any.whl (28 kB)\n",
      "Using cached opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl (14 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl (36 kB)\n",
      "Using cached opentelemetry_util_http-0.45b0-py3-none-any.whl (6.9 kB)\n",
      "Using cached opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n",
      "Using cached orjson-3.10.0-cp310-cp310-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (252 kB)\n",
      "Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Using cached posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
      "Using cached pulsar_client-3.5.0-cp310-cp310-macosx_10_15_universal2.whl (11.0 MB)\n",
      "Using cached tokenizers-0.15.2-cp310-cp310-macosx_10_12_x86_64.whl (2.6 MB)\n",
      "Using cached typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "Using cached uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
      "Using cached importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n",
      "Using cached googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached httptools-0.6.1-cp310-cp310-macosx_10_9_x86_64.whl (77 kB)\n",
      "Using cached huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "Using cached importlib_metadata-7.0.0-py3-none-any.whl (23 kB)\n",
      "Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Using cached protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Using cached uvloop-0.19.0-cp310-cp310-macosx_10_9_x86_64.whl (793 kB)\n",
      "Using cached watchfiles-0.21.0-cp310-cp310-macosx_10_7_x86_64.whl (428 kB)\n",
      "Using cached websocket_client-1.7.0-py3-none-any.whl (58 kB)\n",
      "Using cached websockets-12.0-cp310-cp310-macosx_10_9_x86_64.whl (121 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Using cached asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Using cached cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached zipp-3.18.1-py3-none-any.whl (8.2 kB)\n",
      "Using cached filelock-3.13.4-py3-none-any.whl (11 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "Installing collected packages: pypika, mpmath, monotonic, mmh3, flatbuffers, zipp, websockets, websocket-client, uvloop, uvicorn, tomli, sympy, shellingham, python-dotenv, pyasn1, pulsar-client, protobuf, overrides, orjson, opentelemetry-util-http, opentelemetry-semantic-conventions, oauthlib, mdurl, importlib-resources, humanfriendly, httptools, grpcio, filelock, chroma-hnswlib, cachetools, bcrypt, backoff, asgiref, watchfiles, rsa, requests-oauthlib, pyproject_hooks, pyasn1-modules, posthog, opentelemetry-proto, markdown-it-py, importlib-metadata, huggingface_hub, googleapis-common-protos, coloredlogs, tokenizers, rich, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, onnxruntime, google-auth, build, typer, opentelemetry-sdk, opentelemetry-instrumentation, kubernetes, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb, llama_index.vector_stores.chroma\n",
      "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.1.2 build-1.2.1 cachetools-5.3.3 chroma-hnswlib-0.7.3 chromadb-0.4.24 coloredlogs-15.0.1 filelock-3.13.4 flatbuffers-24.3.25 google-auth-2.29.0 googleapis-common-protos-1.63.0 grpcio-1.62.1 httptools-0.6.1 huggingface_hub-0.22.2 humanfriendly-10.0 importlib-metadata-7.0.0 importlib-resources-6.4.0 kubernetes-29.0.0 llama_index.vector_stores.chroma-0.1.6 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-4.1.0 monotonic-1.6 mpmath-1.3.0 oauthlib-3.2.2 onnxruntime-1.17.3 opentelemetry-api-1.24.0 opentelemetry-exporter-otlp-proto-common-1.24.0 opentelemetry-exporter-otlp-proto-grpc-1.24.0 opentelemetry-instrumentation-0.45b0 opentelemetry-instrumentation-asgi-0.45b0 opentelemetry-instrumentation-fastapi-0.45b0 opentelemetry-proto-1.24.0 opentelemetry-sdk-1.24.0 opentelemetry-semantic-conventions-0.45b0 opentelemetry-util-http-0.45b0 orjson-3.10.0 overrides-7.7.0 posthog-3.5.0 protobuf-4.25.3 pulsar-client-3.5.0 pyasn1-0.6.0 pyasn1-modules-0.4.0 pypika-0.48.9 pyproject_hooks-1.0.0 python-dotenv-1.0.1 requests-oauthlib-2.0.0 rich-13.7.1 rsa-4.9 shellingham-1.5.4 sympy-1.12 tokenizers-0.15.2 tomli-2.0.1 typer-0.12.3 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0 websocket-client-1.7.0 websockets-12.0 zipp-3.18.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install chromadb llama_index.vector_stores.chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "template = (\n",
    "    \"You are helping Marathon Organizers or Marathon Runners to find information\"\n",
    "    \"Please be respectful and provide answers in an energetic way, just like a runner\"\n",
    "    \"We have provided context information below. \\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\"\n",
    "    \"\\n---------------------\\n\"\n",
    "    \"Given this information, please answer the question: {query_str}\\n\"\n",
    ")\n",
    "qa_template = PromptTemplate(template)\n",
    "\n",
    "# Use the custom prompt when querying\n",
    "query_engine = index.as_query_engine(text_qa_template=qa_template)\n",
    "response = query_engine.query(\"who is this text about?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Prompt' from 'llama_index' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Prompt\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Define a custom prompt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m template \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe have provided context information below. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGiven this information, please answer the question and each answer should start with code word AI Demos: \u001b[39m\u001b[38;5;132;01m{query_str}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Prompt' from 'llama_index' (unknown location)"
     ]
    }
   ],
   "source": [
    "from llama_index import Prompt\n",
    "\n",
    "# Define a custom prompt\n",
    "template = (\n",
    "    \"We have provided context information below. \\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\"\n",
    "    \"\\n---------------------\\n\"\n",
    "    \"Given this information, please answer the question and each answer should start with code word AI Demos: {query_str}\\n\"\n",
    ")\n",
    "qa_template = Prompt(template)\n",
    "\n",
    "# Use the custom prompt when querying\n",
    "query_engine = custom_llm_index.as_query_engine(text_qa_template=qa_template)\n",
    "response = query_engine.query(\"who is this text about?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from API:\n",
      "The winner of the Boston Marathon in 2015 was Lelisa Desisa. Desisa did not run a negative split. His overall time was 2 hours, 9 minutes, and 17 seconds, and his time at the 5-kilometer mark was 14 minutes and 48 seconds.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the URL of the API endpoint\n",
    "url = \"http://localhost:8000/get_question/\"\n",
    "\n",
    "# Define the data to be sent in the request body\n",
    "data = {\n",
    "    \"question\": \"who won boston marathon 2015?; did that person run a negative split?; What was this person overall time and 5k time?\"\n",
    "}\n",
    "\n",
    "# Send a POST request to the API endpoint with the data\n",
    "response = requests.get(url, json=data)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Print the response from the API\n",
    "    print(\"Response from API:\")\n",
    "    print(response.json())\n",
    "else:\n",
    "    print(\"Error:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from fastapi.openapi.docs import get_swagger_ui_html\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/items/\")\n",
    "async def read_items():\n",
    "    \"\"\"\n",
    "    Retrieve a list of items.\n",
    "\n",
    "    Returns:\n",
    "        List of items.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "@app.post(\"/items/\")\n",
    "async def create_item():\n",
    "    \"\"\"\n",
    "    Create a new item.\n",
    "\n",
    "    Request Body:\n",
    "        - name: The name of the item.\n",
    "        - description: The description of the item.\n",
    "\n",
    "    Returns:\n",
    "        The created item.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "@app.get(\"/docs/\", include_in_schema=False)\n",
    "async def custom_swagger_ui_html():\n",
    "    return get_swagger_ui_html(openapi_url=\"/openapi.json\", title=\"API Documentation\", oauth2_redirect_url=\"/docs\")\n",
    "\n",
    "@app.get(\"/openapi.json\", include_in_schema=False)\n",
    "async def get_openapi_json():\n",
    "    return app.openapi()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Using cached openai-1.17.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.10/site-packages (from openai) (4.3.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.10/site-packages (from openai) (2.7.0)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in ./.venv/lib/python3.10/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in ./.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.18.1)\n",
      "Using cached openai-1.17.0-py3-none-any.whl (268 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Using cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, httpcore, distro, httpx, openai\n",
      "Successfully installed distro-1.9.0 httpcore-1.0.5 httpx-0.27.0 openai-1.17.0 tqdm-4.66.2\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m----> 2\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      5\u001b[0m   model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m   messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m   ]\n\u001b[1;32m     12\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/jobs tests/tilful/api_2/.venv/lib/python3.10/site-packages/openai/_client.py:100\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m     98\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m     )\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/marathon_results_2015.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Bib</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>M/F</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "      <th>Citizen</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>25K</th>\n",
       "      <th>30K</th>\n",
       "      <th>35K</th>\n",
       "      <th>40K</th>\n",
       "      <th>Pace</th>\n",
       "      <th>Proj Time</th>\n",
       "      <th>Official Time</th>\n",
       "      <th>Overall</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Division</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Desisa, Lelisa</td>\n",
       "      <td>25</td>\n",
       "      <td>M</td>\n",
       "      <td>Ambo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ETH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1:16:07</td>\n",
       "      <td>1:32:00</td>\n",
       "      <td>1:47:59</td>\n",
       "      <td>2:02:39</td>\n",
       "      <td>0:04:56</td>\n",
       "      <td>-</td>\n",
       "      <td>2:09:17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Tsegay, Yemane Adhane</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>Addis Ababa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ETH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1:16:07</td>\n",
       "      <td>1:31:59</td>\n",
       "      <td>1:47:59</td>\n",
       "      <td>2:02:42</td>\n",
       "      <td>0:04:58</td>\n",
       "      <td>-</td>\n",
       "      <td>2:09:48</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>Chebet, Wilson</td>\n",
       "      <td>29</td>\n",
       "      <td>M</td>\n",
       "      <td>Marakwet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1:16:07</td>\n",
       "      <td>1:32:00</td>\n",
       "      <td>1:47:59</td>\n",
       "      <td>2:03:01</td>\n",
       "      <td>0:04:59</td>\n",
       "      <td>-</td>\n",
       "      <td>2:10:22</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>Kipyego, Bernard</td>\n",
       "      <td>28</td>\n",
       "      <td>M</td>\n",
       "      <td>Eldoret</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1:16:07</td>\n",
       "      <td>1:32:00</td>\n",
       "      <td>1:48:03</td>\n",
       "      <td>2:03:47</td>\n",
       "      <td>0:05:00</td>\n",
       "      <td>-</td>\n",
       "      <td>2:10:47</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>Korir, Wesley</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>Kitale</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1:16:07</td>\n",
       "      <td>1:32:00</td>\n",
       "      <td>1:47:59</td>\n",
       "      <td>2:03:27</td>\n",
       "      <td>0:05:00</td>\n",
       "      <td>-</td>\n",
       "      <td>2:10:49</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Bib                   Name  Age M/F         City State Country  \\\n",
       "0           0   3         Desisa, Lelisa   25   M         Ambo   NaN     ETH   \n",
       "1           1   4  Tsegay, Yemane Adhane   30   M  Addis Ababa   NaN     ETH   \n",
       "2           2   8         Chebet, Wilson   29   M     Marakwet   NaN     KEN   \n",
       "3           3  11       Kipyego, Bernard   28   M      Eldoret   NaN     KEN   \n",
       "4           4  10          Korir, Wesley   32   M       Kitale   NaN     KEN   \n",
       "\n",
       "  Citizen Unnamed: 9  ...      25K      30K      35K      40K     Pace  \\\n",
       "0     NaN        NaN  ...  1:16:07  1:32:00  1:47:59  2:02:39  0:04:56   \n",
       "1     NaN        NaN  ...  1:16:07  1:31:59  1:47:59  2:02:42  0:04:58   \n",
       "2     NaN        NaN  ...  1:16:07  1:32:00  1:47:59  2:03:01  0:04:59   \n",
       "3     NaN        NaN  ...  1:16:07  1:32:00  1:48:03  2:03:47  0:05:00   \n",
       "4     NaN        NaN  ...  1:16:07  1:32:00  1:47:59  2:03:27  0:05:00   \n",
       "\n",
       "  Proj Time Official Time Overall Gender Division  \n",
       "0         -       2:09:17       1      1        1  \n",
       "1         -       2:09:48       2      2        2  \n",
       "2         -       2:10:22       3      3        3  \n",
       "3         -       2:10:47       4      4        4  \n",
       "4         -       2:10:49       5      5        5  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = df.loc[df['City'] == 'Coquitlam', ['Country', 'Name', 'Official Time', 'Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Country                 Name Official Time  Age\n",
      "7027      CAN        Weir, Adam J.       3:20:06   47\n",
      "10850     CAN  Hancharyk, Nancy R.       3:32:09   41\n",
      "16083     CAN    Purhar, Neelam K.       3:49:02   48\n",
      "16300     CAN        Kim, Jennifer       3:49:51   38\n",
      "16377     CAN         Yeung, Sidon       3:50:07   60\n",
      "19531     CAN      Falletta, Elisa       4:03:54   55\n",
      "22354     CAN    Beittoei, Alireza       4:24:05   64\n"
     ]
    }
   ],
   "source": [
    "print(selected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing CSV files\n",
    "csv_directory = './cleaned_data'\n",
    "\n",
    "# List to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Iterate over CSV files in the directory\n",
    "for filename in os.listdir(csv_directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Read CSV file into a DataFrame\n",
    "        filepath = os.path.join(csv_directory, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        \n",
    "        # Extract marathon name and year from filename\n",
    "        marathon_name, marathon_year = filename.split('.')[0].split('_')\n",
    "        \n",
    "        # Add columns for marathon name and year\n",
    "        df['marathon_name'] = marathon_name\n",
    "        df['marathon_year'] = marathon_year\n",
    "        \n",
    "        # Append DataFrame to list\n",
    "        dataframes.append(df)\n",
    "\n",
    "# Concatenate DataFrames into a single DataFrame\n",
    "result = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sqlalchemy\n",
      "  Using cached SQLAlchemy-2.0.29-cp310-cp310-macosx_10_9_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in ./.venv/lib/python3.10/site-packages (from sqlalchemy) (4.11.0)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy)\n",
      "  Using cached greenlet-3.0.3-cp310-cp310-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "Using cached SQLAlchemy-2.0.29-cp310-cp310-macosx_10_9_x86_64.whl (2.1 MB)\n",
      "Using cached greenlet-3.0.3-cp310-cp310-macosx_11_0_universal2.whl (270 kB)\n",
      "Installing collected packages: greenlet, sqlalchemy\n",
      "Successfully installed greenlet-3.0.3 sqlalchemy-2.0.29\n"
     ]
    }
   ],
   "source": [
    "!pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Using cached llama_index-0.10.28-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index)\n",
      "  Using cached llama_index_agent_openai-0.2.2-py3-none-any.whl.metadata (677 bytes)\n",
      "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Using cached llama_index_cli-0.1.11-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core<0.11.0,>=0.10.28 (from llama-index)\n",
      "  Using cached llama_index_core-0.10.28-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index)\n",
      "  Using cached llama_index_embeddings_openai-0.1.7-py3-none-any.whl.metadata (603 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Using cached llama_index_indices_managed_llama_cloud-0.1.5-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
      "  Using cached llama_index_legacy-0.9.48-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama-index)\n",
      "  Using cached llama_index_llms_openai-0.1.15-py3-none-any.whl.metadata (559 bytes)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index)\n",
      "  Using cached llama_index_multi_modal_llms_openai-0.1.5-py3-none-any.whl.metadata (677 bytes)\n",
      "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index)\n",
      "  Using cached llama_index_program_openai-0.1.5-py3-none-any.whl.metadata (715 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Using cached llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\n",
      "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index)\n",
      "  Downloading llama_index_readers_file-0.1.17-py3-none-any.whl.metadata (979 bytes)\n",
      "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Using cached llama_index_readers_llama_parse-0.1.4-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.3.0,>=0.1.4->llama-index)\n",
      "  Downloading openai-1.17.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting PyYAML>=6.0.1 (from llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached PyYAML-6.0.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./.venv/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.28->llama-index) (2.0.29)\n",
      "Collecting aiohttp<4.0.0,>=3.8.6 (from llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached aiohttp-3.9.4-cp310-cp310-macosx_10_9_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting dataclasses-json (from llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached dataclasses_json-0.6.4-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting fsspec>=2023.5.0 (from llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx (from llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting llamaindex-py-client<0.2.0,>=0.1.16 (from llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Downloading llamaindex_py_client-0.1.18-py3-none-any.whl.metadata (760 bytes)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (1.6.0)\n",
      "Collecting networkx>=3.0 (from llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting nltk<4.0.0,>=3.8.1 (from llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting numpy (from llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached numpy-1.26.4-cp310-cp310-macosx_10_9_x86_64.whl.metadata (61 kB)\n",
      "Collecting pandas (from llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached pandas-2.2.2-cp310-cp310-macosx_10_9_x86_64.whl.metadata (19 kB)\n",
      "Collecting pillow>=9.0.0 (from llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached pillow-10.3.0-cp310-cp310-macosx_10_10_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting requests>=2.31.0 (from llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tenacity<9.0.0,>=8.2.0 (from llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached tiktoken-0.6.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting tqdm<5.0.0,>=4.66.1 (from llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.28->llama-index) (4.11.0)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting wrapt (from llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached wrapt-1.16.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting beautifulsoup4<5.0.0,>=4.12.3 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Using cached pypdf-4.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Using cached striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse<0.5.0,>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached llama_parse-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached frozenlist-1.4.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached multidict-6.0.5-cp310-cp310-macosx_10_9_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached yarl-1.9.4-cp310-cp310-macosx_10_9_x86_64.whl.metadata (31 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Using cached soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting pydantic>=1.10 (from llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached pydantic-2.7.0-py3-none-any.whl.metadata (103 kB)\n",
      "Collecting anyio (from httpx->llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached anyio-4.3.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting certifi (from httpx->llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting httpcore==1.* (from httpx->llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting idna (from httpx->llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting sniffio (from httpx->llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting click (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached joblib-1.4.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached regex-2023.12.25-cp310-cp310-macosx_10_9_x86_64.whl.metadata (40 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached charset_normalizer-3.3.2-cp310-cp310-macosx_10_9_x86_64.whl.metadata (33 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.venv/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.28->llama-index) (3.0.3)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached marshmallow-3.21.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.28->llama-index) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.28->llama-index) (1.2.0)\n",
      "Requirement already satisfied: packaging>=17.0 in ./.venv/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.28->llama-index) (24.0)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.18.1 (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.28->llama-index)\n",
      "  Using cached pydantic_core-2.18.1-cp310-cp310-macosx_10_12_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.28->llama-index) (1.16.0)\n",
      "Using cached llama_index-0.10.28-py3-none-any.whl (6.9 kB)\n",
      "Using cached llama_index_agent_openai-0.2.2-py3-none-any.whl (12 kB)\n",
      "Using cached llama_index_cli-0.1.11-py3-none-any.whl (26 kB)\n",
      "Using cached llama_index_core-0.10.28-py3-none-any.whl (15.4 MB)\n",
      "Using cached llama_index_embeddings_openai-0.1.7-py3-none-any.whl (6.0 kB)\n",
      "Using cached llama_index_indices_managed_llama_cloud-0.1.5-py3-none-any.whl (6.7 kB)\n",
      "Using cached llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
      "Using cached llama_index_llms_openai-0.1.15-py3-none-any.whl (10 kB)\n",
      "Using cached llama_index_multi_modal_llms_openai-0.1.5-py3-none-any.whl (5.8 kB)\n",
      "Using cached llama_index_program_openai-0.1.5-py3-none-any.whl (4.1 kB)\n",
      "Using cached llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_readers_file-0.1.17-py3-none-any.whl (36 kB)\n",
      "Using cached llama_index_readers_llama_parse-0.1.4-py3-none-any.whl (2.5 kB)\n",
      "Using cached aiohttp-3.9.4-cp310-cp310-macosx_10_9_x86_64.whl (400 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Using cached fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "Using cached llama_parse-0.4.0-py3-none-any.whl (7.0 kB)\n",
      "Downloading llamaindex_py_client-0.1.18-py3-none-any.whl (136 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.1/136.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Downloading openai-1.17.1-py3-none-any.whl (268 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.3/268.3 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pillow-10.3.0-cp310-cp310-macosx_10_10_x86_64.whl (3.5 MB)\n",
      "Using cached pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
      "Using cached PyYAML-6.0.1-cp310-cp310-macosx_10_9_x86_64.whl (189 kB)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Using cached striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Using cached tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Using cached tiktoken-0.6.0-cp310-cp310-macosx_10_9_x86_64.whl (999 kB)\n",
      "Using cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached wrapt-1.16.0-cp310-cp310-macosx_10_9_x86_64.whl (37 kB)\n",
      "Using cached dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Using cached numpy-1.26.4-cp310-cp310-macosx_10_9_x86_64.whl (20.6 MB)\n",
      "Using cached pandas-2.2.2-cp310-cp310-macosx_10_9_x86_64.whl (12.6 MB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached anyio-4.3.0-py3-none-any.whl (85 kB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp310-cp310-macosx_10_9_x86_64.whl (122 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached frozenlist-1.4.1-cp310-cp310-macosx_10_9_x86_64.whl (53 kB)\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
      "Using cached multidict-6.0.5-cp310-cp310-macosx_10_9_x86_64.whl (30 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Using cached pydantic-2.7.0-py3-none-any.whl (407 kB)\n",
      "Using cached pydantic_core-2.18.1-cp310-cp310-macosx_10_12_x86_64.whl (1.9 MB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached regex-2023.12.25-cp310-cp310-macosx_10_9_x86_64.whl (296 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Using cached yarl-1.9.4-cp310-cp310-macosx_10_9_x86_64.whl (81 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached joblib-1.4.0-py3-none-any.whl (301 kB)\n",
      "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: striprtf, pytz, dirtyjson, wrapt, urllib3, tzdata, tqdm, tenacity, soupsieve, sniffio, regex, PyYAML, pypdf, pydantic-core, pillow, numpy, networkx, mypy-extensions, multidict, marshmallow, joblib, idna, h11, fsspec, frozenlist, distro, click, charset-normalizer, certifi, attrs, async-timeout, annotated-types, yarl, typing-inspect, requests, pydantic, pandas, nltk, httpcore, deprecated, beautifulsoup4, anyio, aiosignal, tiktoken, httpx, dataclasses-json, aiohttp, openai, llamaindex-py-client, llama-index-legacy, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "Successfully installed PyYAML-6.0.1 aiohttp-3.9.4 aiosignal-1.3.1 annotated-types-0.6.0 anyio-4.3.0 async-timeout-4.0.3 attrs-23.2.0 beautifulsoup4-4.12.3 certifi-2024.2.2 charset-normalizer-3.3.2 click-8.1.7 dataclasses-json-0.6.4 deprecated-1.2.14 dirtyjson-1.0.8 distro-1.9.0 frozenlist-1.4.1 fsspec-2024.3.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 idna-3.7 joblib-1.4.0 llama-index-0.10.28 llama-index-agent-openai-0.2.2 llama-index-cli-0.1.11 llama-index-core-0.10.28 llama-index-embeddings-openai-0.1.7 llama-index-indices-managed-llama-cloud-0.1.5 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.15 llama-index-multi-modal-llms-openai-0.1.5 llama-index-program-openai-0.1.5 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.17 llama-index-readers-llama-parse-0.1.4 llama-parse-0.4.0 llamaindex-py-client-0.1.18 marshmallow-3.21.1 multidict-6.0.5 mypy-extensions-1.0.0 networkx-3.3 nltk-3.8.1 numpy-1.26.4 openai-1.17.1 pandas-2.2.2 pillow-10.3.0 pydantic-2.7.0 pydantic-core-2.18.1 pypdf-4.2.0 pytz-2024.1 regex-2023.12.25 requests-2.31.0 sniffio-1.3.1 soupsieve-2.5 striprtf-0.0.26 tenacity-8.2.3 tiktoken-0.6.0 tqdm-4.66.2 typing-inspect-0.9.0 tzdata-2024.1 urllib3-2.2.1 wrapt-1.16.0 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index\n",
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m dfs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Iterate over CSV files in the directory\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_directory\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;66;03m# Read CSV file into a DataFrame\u001b[39;00m\n\u001b[1;32m     15\u001b[0m         filepath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(csv_directory, filename)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Directory containing CSV files\n",
    "csv_directory = './data'\n",
    "\n",
    "# Output directory for transformed CSV files\n",
    "output_directory = './cleaned_data'\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "dfs = []\n",
    "# Iterate over CSV files in the directory\n",
    "for filename in os.listdir(csv_directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Read CSV file into a DataFrame\n",
    "        filepath = os.path.join(csv_directory, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        df.columns = ['orig_index', 'bib', 'name', 'age', 'gender', 'city', 'state', 'country','citizenship', 'empty', 'time_at_5_kilometers', 'time_at_10_kilometers', 'time_at_15_kilometers', 'time_at_20_kilometers', 'time_at_21_kilometers', 'time_at_25_kilometers','time_at_30_kilometers', 'time_at_35_kilometers', 'time_at_40_kilometers', 'running_pace', 'projected_time', 'official_time', 'overall_time','place_by_gender', 'place_by_division']\n",
    "        # Extract marathon name and year from filename\n",
    "        marathon_name, marathon_year = filename.split('.')[0].split('_')\n",
    "        \n",
    "        # Add columns for marathon name and year\n",
    "        df['marathon_name'] = marathon_name\n",
    "        df['marathon_year'] = int(marathon_year)\n",
    "        df['marathon_city'] = 'Boston'\n",
    "        \n",
    "        # Append DataFrame to the list\n",
    "        dfs.append(df)\n",
    "        \n",
    "        # Concatenate all DataFrames into one\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "combined_df = combined_df.drop(columns=['orig_index', 'projected_time', 'empty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bib', 'name', 'age', 'gender', 'city', 'state', 'country',\n",
       "       'citizenship', 'time_at_5_kilometers', 'time_at_10_kilometers',\n",
       "       'time_at_15_kilometers', 'time_at_20_kilometers',\n",
       "       'time_at_21_kilometers', 'time_at_25_kilometers',\n",
       "       'time_at_30_kilometers', 'time_at_35_kilometers',\n",
       "       'time_at_40_kilometers', 'running_pace', 'official_time',\n",
       "       'overall_time', 'place_by_gender', 'place_by_division', 'marathon_name',\n",
       "       'marathon_year', 'marathon_city'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bib</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>citizenship</th>\n",
       "      <th>time_at_5_kilometers</th>\n",
       "      <th>time_at_10_kilometers</th>\n",
       "      <th>time_at_15_kilometers</th>\n",
       "      <th>time_at_20_kilometers</th>\n",
       "      <th>time_at_21_kilometers</th>\n",
       "      <th>time_at_25_kilometers</th>\n",
       "      <th>time_at_30_kilometers</th>\n",
       "      <th>time_at_35_kilometers</th>\n",
       "      <th>time_at_40_kilometers</th>\n",
       "      <th>running_pace</th>\n",
       "      <th>official_time</th>\n",
       "      <th>overall_time</th>\n",
       "      <th>place_by_gender</th>\n",
       "      <th>place_by_division</th>\n",
       "      <th>marathon_name</th>\n",
       "      <th>marathon_year</th>\n",
       "      <th>marathon_city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Desisa, Lelisa</td>\n",
       "      <td>25</td>\n",
       "      <td>M</td>\n",
       "      <td>Ambo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ETH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0:14:43</td>\n",
       "      <td>0:29:43</td>\n",
       "      <td>0:44:57</td>\n",
       "      <td>1:00:29</td>\n",
       "      <td>1:04:02</td>\n",
       "      <td>1:16:07</td>\n",
       "      <td>1:32:00</td>\n",
       "      <td>1:47:59</td>\n",
       "      <td>2:02:39</td>\n",
       "      <td>0:04:56</td>\n",
       "      <td>2:09:17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Boston</td>\n",
       "      <td>2015</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Tsegay, Yemane Adhane</td>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>Addis Ababa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ETH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0:14:43</td>\n",
       "      <td>0:29:43</td>\n",
       "      <td>0:44:58</td>\n",
       "      <td>1:00:28</td>\n",
       "      <td>1:04:01</td>\n",
       "      <td>1:16:07</td>\n",
       "      <td>1:31:59</td>\n",
       "      <td>1:47:59</td>\n",
       "      <td>2:02:42</td>\n",
       "      <td>0:04:58</td>\n",
       "      <td>2:09:48</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Boston</td>\n",
       "      <td>2015</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Chebet, Wilson</td>\n",
       "      <td>29</td>\n",
       "      <td>M</td>\n",
       "      <td>Marakwet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0:14:43</td>\n",
       "      <td>0:29:43</td>\n",
       "      <td>0:44:57</td>\n",
       "      <td>1:00:29</td>\n",
       "      <td>1:04:02</td>\n",
       "      <td>1:16:07</td>\n",
       "      <td>1:32:00</td>\n",
       "      <td>1:47:59</td>\n",
       "      <td>2:03:01</td>\n",
       "      <td>0:04:59</td>\n",
       "      <td>2:10:22</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Boston</td>\n",
       "      <td>2015</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>Kipyego, Bernard</td>\n",
       "      <td>28</td>\n",
       "      <td>M</td>\n",
       "      <td>Eldoret</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0:14:43</td>\n",
       "      <td>0:29:44</td>\n",
       "      <td>0:45:01</td>\n",
       "      <td>1:00:29</td>\n",
       "      <td>1:04:02</td>\n",
       "      <td>1:16:07</td>\n",
       "      <td>1:32:00</td>\n",
       "      <td>1:48:03</td>\n",
       "      <td>2:03:47</td>\n",
       "      <td>0:05:00</td>\n",
       "      <td>2:10:47</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Boston</td>\n",
       "      <td>2015</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Korir, Wesley</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>Kitale</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0:14:43</td>\n",
       "      <td>0:29:44</td>\n",
       "      <td>0:44:58</td>\n",
       "      <td>1:00:28</td>\n",
       "      <td>1:04:01</td>\n",
       "      <td>1:16:07</td>\n",
       "      <td>1:32:00</td>\n",
       "      <td>1:47:59</td>\n",
       "      <td>2:03:27</td>\n",
       "      <td>0:05:00</td>\n",
       "      <td>2:10:49</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Boston</td>\n",
       "      <td>2015</td>\n",
       "      <td>Boston</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  bib                   name age gender         city state country  \\\n",
       "0   3         Desisa, Lelisa  25      M         Ambo   NaN     ETH   \n",
       "1   4  Tsegay, Yemane Adhane  30      M  Addis Ababa   NaN     ETH   \n",
       "2   8         Chebet, Wilson  29      M     Marakwet   NaN     KEN   \n",
       "3  11       Kipyego, Bernard  28      M      Eldoret   NaN     KEN   \n",
       "4  10          Korir, Wesley  32      M       Kitale   NaN     KEN   \n",
       "\n",
       "  citizenship time_at_5_kilometers time_at_10_kilometers  \\\n",
       "0         NaN              0:14:43               0:29:43   \n",
       "1         NaN              0:14:43               0:29:43   \n",
       "2         NaN              0:14:43               0:29:43   \n",
       "3         NaN              0:14:43               0:29:44   \n",
       "4         NaN              0:14:43               0:29:44   \n",
       "\n",
       "  time_at_15_kilometers time_at_20_kilometers time_at_21_kilometers  \\\n",
       "0               0:44:57               1:00:29               1:04:02   \n",
       "1               0:44:58               1:00:28               1:04:01   \n",
       "2               0:44:57               1:00:29               1:04:02   \n",
       "3               0:45:01               1:00:29               1:04:02   \n",
       "4               0:44:58               1:00:28               1:04:01   \n",
       "\n",
       "  time_at_25_kilometers time_at_30_kilometers time_at_35_kilometers  \\\n",
       "0               1:16:07               1:32:00               1:47:59   \n",
       "1               1:16:07               1:31:59               1:47:59   \n",
       "2               1:16:07               1:32:00               1:47:59   \n",
       "3               1:16:07               1:32:00               1:48:03   \n",
       "4               1:16:07               1:32:00               1:47:59   \n",
       "\n",
       "  time_at_40_kilometers running_pace official_time  overall_time  \\\n",
       "0               2:02:39      0:04:56       2:09:17             1   \n",
       "1               2:02:42      0:04:58       2:09:48             2   \n",
       "2               2:03:01      0:04:59       2:10:22             3   \n",
       "3               2:03:47      0:05:00       2:10:47             4   \n",
       "4               2:03:27      0:05:00       2:10:49             5   \n",
       "\n",
       "   place_by_gender  place_by_division marathon_name  marathon_year  \\\n",
       "0                1                1.0        Boston           2015   \n",
       "1                2                2.0        Boston           2015   \n",
       "2                3                3.0        Boston           2015   \n",
       "3                4                4.0        Boston           2015   \n",
       "4                5                5.0        Boston           2015   \n",
       "\n",
       "  marathon_city  \n",
       "0        Boston  \n",
       "1        Boston  \n",
       "2        Boston  \n",
       "3        Boston  \n",
       "4        Boston  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_columns = 30\n",
    "\n",
    "combined_df[combined_df.marathon_year == 2015].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import (\n",
    "    create_engine,\n",
    "    MetaData,\n",
    "    Table,\n",
    "    Column,\n",
    "    String,\n",
    "    Integer,\n",
    "    select,\n",
    "    column,\n",
    ")\n",
    "\n",
    "from llama_index.core import SQLDatabase\n",
    "\n",
    "engine = create_engine('sqlite:///./db/marathon.db')\n",
    "sql_database = SQLDatabase(engine, include_tables=[\"marathon_results\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY exported successfully.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.query_engine import NLSQLTableQueryEngine\n",
    "from src.utils import load_key\n",
    "load_key() # Setup OPENAI Key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_engine = NLSQLTableQueryEngine(\n",
    "    sql_database=sql_database,\n",
    "    tables=[\"marathon_results\"],\n",
    ")\n",
    "#query_str = \"based on the context, who ran with bib 25651 in boston 2015? and time? time at half race? did he did a negative split?\"\n",
    "query_str = \"based on the context take top 5 overall_time of boston 2015 and and list only those who ran a negative split taking official time and half race time?\"\n",
    "response = query_engine.query(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 overall times for the Boston 2015 marathon are as follows: \n",
      "1. Desisa, Lelisa - Official Time: 2:09:17, Half Race Time: 1:04:02\n",
      "2. Shafar, Vitaliy - Official Time: 2:13:52, Half Race Time: 1:05:07\n",
      "3. Ausen, Cameron - Official Time: 2:32:05, Half Race Time: 1:15:47\n",
      "4. Lira, Chuy - Official Time: 2:50:35, Half Race Time: 1:16:25\n",
      "5. Vanbuskirk, Jason - Official Time: 3:29:33, Half Race Time: 1:40:04\n",
      "\n",
      "These runners all achieved a negative split, running the second half of the race faster than the first half.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\") # \"text-embedding-ada-002\"  <- default  other option -> model=\"text-embedding-3-small\"\n",
    "# Settings.num_output = 512\n",
    "# Settings.context_window = 3900\n",
    "# Settings.chunk_size = 1000\n",
    "# Settings.chunk_overlap = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.objects import (\n",
    "    SQLTableNodeMapping,\n",
    "    ObjectIndex,\n",
    "    SQLTableSchema,\n",
    ")\n",
    "from llama_index.core import VectorStoreIndex\n",
    "import chromadb\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "db = chromadb.PersistentClient(path=\"./chroma_db\") # initialize client, setting path to save data\n",
    "# create collection\n",
    "chroma_collection = db.get_or_create_collection(\"boston_marathon\")\n",
    "# assign chroma as the vector_store to the context\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  3.98it/s]\n"
     ]
    }
   ],
   "source": [
    "# manually set extra context text\n",
    "marathon_results_text = (\n",
    "    \"This table stores information regarding the finishers of the Boston Marathon of 2015, 2016 and 2017.\\n\"\n",
    "    \"Description of this table was taken from the metadata of the original files obtained from Kaggle.\"\n",
    "    \"It's important to highlight that the Boston Marathon is the oldest marathon run in the US as it is the only\" \n",
    "    \"marathon (other than olympic trails) that most of the participants have to qualify to participate.\\n\"\n",
    "    \"For the professional runners, it's a big accomplishment to win the marathon.\"\n",
    "    \" For most of the other participants, it's an honor to be part of it.\\n\"\n",
    "    \"Content:\\n\\nIt contains the name which is the name of the runner formated as '[First Name],[Last Name]', it also contains other fileds which names are self descriptive\\n\\n\"\n",
    "    \"# Acknowledgements:\\n\\nData was scrapped from the official marathon website - http://registration.baa.org/2017/cf/Public/iframe_ResultsSearch.cfm\\n\\n\"\n",
    "    \"Link: https://www.kaggle.com/datasets/rojour/boston-results\\n\"\n",
    "    \"Author: Rojour https://www.kaggle.com/rojour\"\n",
    ")\n",
    "\n",
    "table_node_mapping = SQLTableNodeMapping(sql_database)\n",
    "table_schema_objs = [\n",
    "    (SQLTableSchema(table_name=\"marathon_results\", context_str=marathon_results_text))\n",
    "]\n",
    "\n",
    "\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    table_schema_objs,\n",
    "    table_node_mapping,\n",
    "    index_cls = VectorStoreIndex,\n",
    "    storage_context=storage_context,\n",
    "    embed_model=Settings.embed_model,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'obj_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mobjects\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ObjectIndex\n\u001b[0;32m----> 2\u001b[0m object_retriever \u001b[38;5;241m=\u001b[39m \u001b[43mobj_index\u001b[49m\u001b[38;5;241m.\u001b[39mas_retriever(similarity_top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m object_retriever\u001b[38;5;241m.\u001b[39mretrieve(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthor?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'obj_index' is not defined"
     ]
    }
   ],
   "source": [
    "from llama_index.core.objects import ObjectIndex\n",
    "object_retriever = obj_index.as_retriever(similarity_top_k=1)\n",
    "object_retriever.retrieve(\"author?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SQLTableNodeMapping' object has no attribute 'as_retriever'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstruct_store\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SQLTableRetrieverQueryEngine\n\u001b[1;32m      3\u001b[0m query_engine \u001b[38;5;241m=\u001b[39m SQLTableRetrieverQueryEngine(\n\u001b[0;32m----> 4\u001b[0m     sql_database, \u001b[43mobject_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_retriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimilarity_top_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m response \u001b[38;5;241m=\u001b[39m query_engine\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbased on the context take top 5 overall_time of boston 2015 and and list only those who ran a negative split taking official time and half race time?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[0;32m~/Documents/jobs tests/tilful/marathon_llm_app_sql/.venv/lib/python3.10/site-packages/llama_index/core/objects/base.py:209\u001b[0m, in \u001b[0;36mObjectIndex.as_retriever\u001b[0;34m(self, node_postprocessors, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mas_retriever\u001b[39m(\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    205\u001b[0m     node_postprocessors: Optional[List[BaseNodePostprocessor]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    207\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ObjectRetriever:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ObjectRetriever(\n\u001b[0;32m--> 209\u001b[0m         retriever\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_retriever\u001b[49m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs),\n\u001b[1;32m    210\u001b[0m         object_node_mapping\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object_node_mapping,\n\u001b[1;32m    211\u001b[0m         node_postprocessors\u001b[38;5;241m=\u001b[39mnode_postprocessors,\n\u001b[1;32m    212\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SQLTableNodeMapping' object has no attribute 'as_retriever'"
     ]
    }
   ],
   "source": [
    "\n",
    "from llama_index.core.indices.struct_store import SQLTableRetrieverQueryEngine\n",
    "\n",
    "query_engine = SQLTableRetrieverQueryEngine(\n",
    "    sql_database, object_index.as_retriever(similarity_top_k=1)\n",
    ")\n",
    "response = query_engine.query(\"based on the context take top 5 overall_time of boston 2015 and and list only those who ran a negative split taking official time and half race time?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload from db\n",
    "import chromadb\n",
    "from llama_index.core import VectorStoreIndex\n",
    "import chromadb\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core.objects import (ObjectIndex,\n",
    "SQLTableNodeMapping,\n",
    "SQLTableSchema,\n",
    ")\n",
    "\n",
    "from llama_index.core import SQLDatabase\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///./db/marathon.db')\n",
    "sql_database = SQLDatabase(engine, include_tables=[\"marathon_results\"])\n",
    "\n",
    "# manually set extra context text\n",
    "marathon_results_text = (\n",
    "    \"This table stores information regarding the finishers of the Boston Marathon of 2015, 2016 and 2017.\\n\"\n",
    "    \"Description of this table was taken from the metadata of the original files obtained from Kaggle.\"\n",
    "    \"It's important to highlight that the Boston Marathon is the oldest marathon run in the US as it is the only\" \n",
    "    \"marathon (other than olympic trails) that most of the participants have to qualify to participate.\\n\"\n",
    "    \"For the professional runners, it's a big accomplishment to win the marathon.\"\n",
    "    \" For most of the other participants, it's an honor to be part of it.\\n\"\n",
    "    \"Content:\\n\\nIt contains the name which is the name of the runner formated as '[First Name],[Last Name]', it also contains other fileds which names are self descriptive\\n\\n\"\n",
    "    \"# Acknowledgements:\\n\\nData was scrapped from the official marathon website - http://registration.baa.org/2017/cf/Public/iframe_ResultsSearch.cfm\\n\\n\"\n",
    "    \"Link: https://www.kaggle.com/datasets/rojour/boston-results\\n\"\n",
    "    \"Author: Rojour https://www.kaggle.com/rojour\"\n",
    ")\n",
    "\n",
    "table_node_mapping = SQLTableNodeMapping(sql_database)\n",
    "table_schema_objs = [\n",
    "    (SQLTableSchema(table_name=\"marathon_results\", context_str=marathon_results_text))\n",
    "]\n",
    "\n",
    "db = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "chroma_collection = db.get_or_create_collection(\"boston_marathon\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(vector_store=vector_store)\n",
    "\n",
    "object_index = ObjectIndex.from_objects_and_index(table_schema_objs,table_node_mapping, index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SQLTableNodeMapping' object has no attribute 'as_retriever'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m object_retriever \u001b[38;5;241m=\u001b[39m \u001b[43mobject_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_retriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimilarity_top_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m object_retriever\u001b[38;5;241m.\u001b[39mretrieve(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthor?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/jobs tests/tilful/marathon_llm_app_sql/.venv/lib/python3.10/site-packages/llama_index/core/objects/base.py:209\u001b[0m, in \u001b[0;36mObjectIndex.as_retriever\u001b[0;34m(self, node_postprocessors, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mas_retriever\u001b[39m(\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    205\u001b[0m     node_postprocessors: Optional[List[BaseNodePostprocessor]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    207\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ObjectRetriever:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ObjectRetriever(\n\u001b[0;32m--> 209\u001b[0m         retriever\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_retriever\u001b[49m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs),\n\u001b[1;32m    210\u001b[0m         object_node_mapping\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object_node_mapping,\n\u001b[1;32m    211\u001b[0m         node_postprocessors\u001b[38;5;241m=\u001b[39mnode_postprocessors,\n\u001b[1;32m    212\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SQLTableNodeMapping' object has no attribute 'as_retriever'"
     ]
    }
   ],
   "source": [
    "object_retriever = object_index.as_retriever(similarity_top_k=1)\n",
    "object_retriever.retrieve(\"author?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SQLTableNodeMapping' object has no attribute 'as_retriever'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstruct_store\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SQLTableRetrieverQueryEngine\n\u001b[1;32m      3\u001b[0m query_engine \u001b[38;5;241m=\u001b[39m SQLTableRetrieverQueryEngine(\n\u001b[0;32m----> 4\u001b[0m     sql_database, \u001b[43mobject_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_retriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimilarity_top_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m response \u001b[38;5;241m=\u001b[39m query_engine\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhich city has the highest population?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[0;32m~/Documents/jobs tests/tilful/marathon_llm_app_sql/.venv/lib/python3.10/site-packages/llama_index/core/objects/base.py:209\u001b[0m, in \u001b[0;36mObjectIndex.as_retriever\u001b[0;34m(self, node_postprocessors, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mas_retriever\u001b[39m(\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    205\u001b[0m     node_postprocessors: Optional[List[BaseNodePostprocessor]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    207\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ObjectRetriever:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ObjectRetriever(\n\u001b[0;32m--> 209\u001b[0m         retriever\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_retriever\u001b[49m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs),\n\u001b[1;32m    210\u001b[0m         object_node_mapping\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object_node_mapping,\n\u001b[1;32m    211\u001b[0m         node_postprocessors\u001b[38;5;241m=\u001b[39mnode_postprocessors,\n\u001b[1;32m    212\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SQLTableNodeMapping' object has no attribute 'as_retriever'"
     ]
    }
   ],
   "source": [
    "from llama_index.core.indices.struct_store import SQLTableRetrieverQueryEngine\n",
    "\n",
    "query_engine = SQLTableRetrieverQueryEngine(\n",
    "    sql_database, object_index.as_retriever(similarity_top_k=1)\n",
    ")\n",
    "response = query_engine.query(\"Which city has the highest population?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Project Architecture\n",
    "\n",
    "## High-Level Architecture\n",
    "The RAG project consists of the following components:\n",
    "- LLM orchestrator: LlamaIndex\n",
    "- LLM: OpenAI\n",
    "- Embeddings: OpenAIEmbedding(model=\"text-embedding-3-small\") \n",
    "- Relational data: Sqlite\n",
    "- Vector Store: ChromaDB\n",
    "- API Interface: FastAPI.\n",
    "\n",
    "## Data Flow\n",
    "1. Data loaded from Kaggle in csv format.\n",
    "2. Data cleaned and loaded to Sqlite. (script:./etl/1_data_loading.py)\n",
    "3. Vector generated and stored in Chroma DB (script:./etl/2_data_indexing.py)\n",
    "4. Input Query: User provides a natural language query.\n",
    "5. Retrieval: Retriever module retrieves vectors from the vector store.\n",
    "6. Generation: Generator module generates a response based on the retrieved information and input query.\n",
    "7. Output Response: The generated response is returned to the user.\n",
    "\n",
    "## Constraints\n",
    "- Maximum Query Length: Input queries are limited to a maximum length to ensure efficient processing.\n",
    "- Model Size: The size of the generative model may impose constraints on memory and computational resources.\n",
    "1. Data Model. Due to time constrains data model is a denormalized table. For future improvements this model would store data as follows:\n",
    "Create a dimenson model following star schema. Fact Table: Results of marathoners. Time Dimension: Date and timeinformation. Marathon dimension: Marathon name, description and characteristics. Geography dimension to store countries and cities. Runers Dimension to store runners names and other information like category (Slowly changing dimension).\n",
    "\n",
    "2. This app would conisder to cache embeddings when it grows, this will make it scalable and efficient. Because this is a POC and there si not much data this was nos considered.\n",
    "\n",
    "3. I considered to use structured data from marathons, because I am a marathon runner and is a project that would help marathon organizers to find useful information about runners without the need to learn sql or other methods.\n",
    "\n",
    "## Dependencies\n",
    "- Python 3.10.8\n",
    "- LLama Index\n",
    "- Open AI\n",
    "- FastAPI\n",
    "- Pydantic\n",
    "- Pandas\n",
    "- Sqlalchemy\n",
    "- ChromaDB\n",
    "\n",
    "## Data Source\n",
    "Acknowledgements: \n",
    "    Data obtained from Kaggle https://www.kaggle.com/datasets/rojour/boston-results.\n",
    "    Author: Rojour https://www.kaggle.com/rojour\n",
    "    Data was scrapped from the official marathon website - http://registration.baa.org/2017/cf/Public/iframe_ResultsSearch.cfm\\n\\n\"\n",
    "\n",
    "## Scalability and Performance\n",
    "The RAG project is designed to scale with large datasets and handle multiple concurrent requests efficiently. Performance optimizations are implemented to minimize response latency.\n",
    "\n",
    "## Project Structure\n",
    "\n",
    "The project directory structure is organized as follows:\n",
    "\n",
    "Root/\n",
    "│\n",
    "├── config/\n",
    "│\n",
    "├── src/\n",
    "│\n",
    "├── etl/\n",
    "│\n",
    "├── db/\n",
    "│\n",
    "├── chromadb/\n",
    "│\n",
    "├── raw_data/\n",
    "│\n",
    "└── test/\n",
    "\n",
    "\n",
    "## Root Directory (/root)\n",
    "\n",
    "The root directory serves as the main directory for the project.\n",
    "\n",
    "- **src**: Contains the source code files for the project.\n",
    "- **etl**: Contains scripts related to Extract, Transform, Load (ETL) processes.\n",
    "- **db**: Contains database-related files.\n",
    "- **chromadb**: Contains files related to vector databases.\n",
    "- **test**: Contains test scripts for testing the project.\n",
    "\n",
    "### Source Directory (/root/src)\n",
    "\n",
    "The source directory contains the main source code files for the project.\n",
    "\n",
    "### ETL Directory (/root/etl)\n",
    "\n",
    "The ETL directory contains scripts or modules related to Extract, Transform, Load (ETL) processes.\n",
    "\n",
    "### Database Directory (/root/db)\n",
    "\n",
    "The database directory contains database-related files or scripts.\n",
    "\n",
    "### Vector Database Directory (/root/vectordb)\n",
    "\n",
    "The vectordb directory contains files or modules related to vector databases.\n",
    "\n",
    "### Test Directory (/root/test)\n",
    "\n",
    "The test directory contains test files or scripts for testing the project.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
